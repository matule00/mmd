{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matule00/mmd/blob/main/code/01ZLMA_ex09_Poisson_01_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-i6MbNFm4Zt"
      },
      "source": [
        "# 01ZLMA - Exercise 09\n",
        "Exercise 09 of the course 01ZLMA.\n",
        "\n",
        "## Contents\n",
        "\n",
        "* Log-linear models with Poisson distributed data\n",
        "* Example from the Lecture 10 (Section 7.7. from lecture notes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Poission regression\n",
        "\n",
        "Poission regression is good for modeling random variables expressing the number of occurs of independent events in given time period.  \n",
        "It also proves to be more suitable for binomial data if the number of repetitions is large and the probability of success low.\n",
        "\n",
        "\n",
        "*   $Y_1, \\ldots, Y_n$ $iid$ $Y_i \\sim Po(\\mu_i)$, where $\\mu_i = s_i λ_i$ and $s_i$ is known sample size.\n",
        "\n",
        "\n",
        "*   Canonical link function $g(x) = ln(x)$: $\\eta_i = g(\\mu_i) = ln(\\mu_i) = ln(s_i) + ln(\\lambda_i) = ln(s_i) + x_i^T \\beta$, where $i= 1,\\ldots, n$ and $\\mu_i = E[Y_i] = s_i\\lambda_i = s_i e^{x_i^T \\beta} = e^{ln(s_i) + {x_i^T \\beta}}$.\n",
        "\n",
        "where $ln(si)$ is called an offset.\n",
        "\n",
        "Average number of events per unit of time/sample size is given by: $λ_i = \\frac{E[Y_i]}{s_i}$\"\n",
        "\n"
      ],
      "metadata": {
        "id": "96rTf2Uoozk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: What is the estimated regresion parametr corresponding to offset?"
      ],
      "metadata": {
        "id": "oFxLKe9NLYkO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIanAJYiLX4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "12CqLkzKFWmY"
      },
      "source": [
        "Let us assume exercise 7.7 from lecture notes (Dobson 9.2.1) - British doctors' smoking and coronary death. (https://reneues.files.wordpress.com/2010/01/an-introduction-to-generalized-linear-models-second-edition-dobson.pdf)\n",
        "\n",
        "Data from the famous doctors study of smoking conducted by Sir Richard Doll and colleagues.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "bQCbWtZq-mYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please note that this cell works may not work in other env-s that Google Colab\n",
        "!pip install wget\n",
        "import wget\n",
        "url = \"https://github.com/francji1/01ZLMA/raw/main/code/helpers.py\"\n",
        "wget.download(url, '../content/helpers.py')  # path where Colab can find libraries\n",
        "from helpers import Anova"
      ],
      "metadata": {
        "id": "zeLOVyAeMiT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dfply\n",
        "from dfply import *  # handy module to mimic R dplyr library"
      ],
      "metadata": {
        "id": "7yblaKje_Nlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_poiss_url = \"https://raw.githubusercontent.com/francji1/01ZLMA/main/data/smoke.csv\"\n",
        "data_poiss = pd.read_csv(data_poiss_url, sep=';')\n"
      ],
      "metadata": {
        "id": "P05vNiBTBimA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_poiss"
      ],
      "metadata": {
        "id": "oxB8M1XH86u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the R magic extension\n",
        "%load_ext rpy2.ipython\n"
      ],
      "metadata": {
        "id": "UMmDAQw8-2nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R -o doctors\n",
        "install.packages(\"dobson\")\n",
        "library(dobson)\n",
        "data(doctors)\n",
        "? doctors"
      ],
      "metadata": {
        "id": "ZIRd2jQU-4LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw0CCzYjIrGO"
      },
      "source": [
        "doctors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "remove_input"
        ],
        "id": "V66n_cKpFWmZ"
      },
      "source": [
        "df = data_poiss.copy()\n",
        "df['age_avg'] = [40, 50, 60, 70, 80, 40, 50, 60, 70, 80]\n",
        "df['age_min'] = [35, 45, 55, 65, 75, 35, 45, 55, 65, 75]\n",
        "df['n_min'] = np.ceil(df['person_years'] / (df['age_min'] - 10))\n",
        "df['n_avg'] = np.ceil(df['person_years'] / (df['age_avg'] - 10))\n",
        "df['living'] = df['n_min'] - df['deaths']\n",
        "df['death_rate'] = df['deaths'] / (df['person_years'] / 10000)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a death rate: the number of deaths per 10,000 person years:\n",
        "$$ \\text{death_rate} = \\frac{deaths}{\\frac{\\text{person_years}}{10000}}$$\n"
      ],
      "metadata": {
        "id": "f-byDboqBiNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_factor_smoke = pd.api.types.is_categorical_dtype(data_poiss['smoke'])\n",
        "print(is_factor_smoke)\n",
        "\n",
        "# Convert 'smoke' to a categorical type\n",
        "data_poiss['smoke'] = data_poiss['smoke'].astype('category')\n",
        "\n",
        "# Convert 'age_group' to a numeric category type\n",
        "data_poiss['agecat'] = data_poiss['age_group'].astype('category').cat.codes\n"
      ],
      "metadata": {
        "id": "irE1syHOAyqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['agecat'] = data_poiss['agecat']"
      ],
      "metadata": {
        "id": "zaBq4tM_DzI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "eB3LjXniKUN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_poiss"
      ],
      "metadata": {
        "id": "-Ptm37rEKauz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "bdRKoj31FWma"
      },
      "source": [
        "## The simplest additive model\n",
        "We start with the simplest model with the variables `smoke` and `agecat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "lSFqOAEsFWma"
      },
      "source": [
        "# Define the model formula without including the offset in the formula string\n",
        "formula = 'deaths ~  smoke + agecat'\n",
        "\n",
        "# Define the offset\n",
        "offset = np.log(data_poiss['person_years'])\n",
        "\n",
        "# Fit the Poisson regression model\n",
        "mdl = smf.glm(formula=formula, data=data_poiss, offset=offset,\n",
        "              family=sm.families.Poisson(link=sm.families.links.Log())).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the log of person years and add it as a new column\n",
        "exposure = (data_poiss['person_years'])\n",
        "# Include the pre-calculated offset column directly in the formula\n",
        "formula = 'deaths ~ smoke + agecat'\n",
        "\n",
        "# Fit the Poisson regression model\n",
        "mdl = smf.glm(formula=formula, data=data_poiss,\n",
        "              exposure=exposure,  family=sm.families.Poisson()).fit(method='bfgs')\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl.summary())"
      ],
      "metadata": {
        "id": "Ww8gC7ZPzEB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "FjOKcZPLFWmc"
      },
      "source": [
        "Deviation statistics have huge value and the model doesn't fit the data that well.\n",
        "We show the dependence of the logarithm of the scaled Y values on the variable agecat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig.align": "center",
        "fig.height": 3.5,
        "fig.width": 4,
        "lines_to_next_cell": 0,
        "results": "asis",
        "id": "PlMOSAD4FWmd"
      },
      "source": [
        "# Calculate the scaled deaths\n",
        "data_poiss['y_scaled'] = data_poiss['deaths'] / data_poiss['person_years'] * 100000\n",
        "\n",
        "# Prepare to plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot data: different markers and colors based on the 'smoke' category\n",
        "for smoke_category in [0, 1]:\n",
        "    subset = data_poiss[data_poiss['smoke'] == smoke_category]\n",
        "    plt.scatter(subset['agecat'], np.log(subset['y_scaled']),\n",
        "                marker='o' if smoke_category == 0 else 's',\n",
        "                color='red' if smoke_category == 0 else 'blue',\n",
        "                s=120,  # equivalent to cex in R\n",
        "                label=f'Smoke={smoke_category}')\n",
        "\n",
        "# Setting up the plot labels and title\n",
        "plt.xlabel('Age Category')\n",
        "plt.ylabel('Log of Deaths per 100,000 Person Years')\n",
        "plt.title('Log of Scaled Deaths by Age Category and Smoking Status')\n",
        "plt.legend(title='Smoking Status')\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9k9Z3xrFWmd"
      },
      "source": [
        "\n",
        "\n",
        "It is clear that the relationship is not linear, so we will add the variable agecat^2 to the model\n",
        "\n",
        "## Model with a quadratic dependence on age - Model 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "HcSbcg7-FWmd"
      },
      "source": [
        "# Define the offset\n",
        "offset = np.log(data_poiss['person_years'])\n",
        "\n",
        "# Define the model formula to include the quadratic term for 'agecat'\n",
        "formula_0 = 'deaths ~  smoke + agecat + I(agecat ** 2)'\n",
        "\n",
        "# Fit the Poisson regression model with the corrected link function (using Log due to deprecation of 'log')\n",
        "mdl_0 = smf.glm(formula=formula_0, data=data_poiss,  offset=offset,\n",
        "\n",
        "                family=sm.families.Poisson(link=sm.families.links.Log())).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl_0.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "RyouT3OkFWmd"
      },
      "source": [
        "All regressors in the model are significant and the value of the deviance statistic has dropped to 12.176; let's compare it with the critical value of the LRT test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "DylN8vYhFWme"
      },
      "source": [
        "from scipy.stats import chi2\n",
        "\n",
        "# Extract the model matrix\n",
        "Xm = mdl_0.model.exog\n",
        "n = Xm.shape[0]  # number of rows in the model matrix\n",
        "p = Xm.shape[1]  # number of parameters in the model\n",
        "\n",
        "# Print the model matrix, n and p\n",
        "print(\"Model Matrix (Xm):\\n\", Xm)\n",
        "print(\"Number of rows (n):\", n)\n",
        "print(\"Number of parameters (p):\", p)\n",
        "\n",
        "# Calculate critical value using the chi-squared distribution\n",
        "c_val = chi2.ppf(0.95, df=n-p)\n",
        "print(\"Critical value (c_val):\", c_val)\n",
        "\n",
        "# Calculate p-value using the model's deviance and degrees of freedom\n",
        "p_val = chi2.sf(mdl_0.deviance, df=n-p)  # sf is the survival function, equivalent to 1-cdf\n",
        "print(\"P-value (p_val):\", p_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "o6OtS0EpFWme"
      },
      "source": [
        "We did not reject the **hypothesis** that the model describes the data well at the 5% significance level. Let's try adding an interaction to the model (a potential change in dependence on smoking with increasing age was visible in the lecture slide).\n",
        "\n",
        "## Model with quadratic age dependence and interaction - Model 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model formula to include the interaction term between 'smoke' and 'agecat'\n",
        "formula = 'deaths ~ smoke + agecat + I(agecat ** 2) + smoke:agecat'\n",
        "\n",
        "# Fit the Poisson regression model with the Log link function\n",
        "mdl_1 = smf.glm(formula=formula, data=data_poiss, offset = offset,\n",
        "                family=sm.families.Poisson(link=sm.families.links.Log())).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl_1.summary())\n"
      ],
      "metadata": {
        "id": "CKxAmKuLIb3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "9iAuydtWFWmf"
      },
      "source": [
        "All variables in the model are significant and the deviance statistic value has dropped to 1.6354. We will get the critical value for the LRT test."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the model matrix\n",
        "Xm = mdl_1.model.exog\n",
        "n = Xm.shape[0]  # number of rows in the model matrix\n",
        "p = Xm.shape[1]  # number of parameters in the model\n",
        "\n",
        "# Print the number of observations and parameters\n",
        "print(\"Number of observations (n):\", n)\n",
        "print(\"Number of parameters (p):\", p)\n",
        "\n",
        "# Calculate the critical value using the chi-squared distribution\n",
        "c_val = chi2.ppf(0.95, df=n-p)\n",
        "print(\"Critical value (c_val):\", c_val)\n",
        "\n",
        "# Calculate the p-value using the model's deviance and degrees of freedom\n",
        "p_val = chi2.sf(mdl_1.deviance, df=n-p)  # sf is the survival function, equivalent to 1-cdf\n",
        "print(\"P-value (p_val):\", p_val)\n"
      ],
      "metadata": {
        "id": "XVpJBNXcIjYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "tno0O6LVFWmf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sQT7iswFWmf"
      },
      "source": [
        "We do not reject the hypothesis of model adequacy with a p-value of 0.897. This indicates that the model describes the data well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RCy7GquFWmf"
      },
      "source": [
        "For illustration, let's also compute the value of the deviance statistic using the formula from the lecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LRT Test for Poison regression by Deviance stistics:\n",
        "$$S = 2\\sum_{i=1}^n \\left[ y_i (ln(\\frac{y_i}{s_i}) - x_i^T \\hat{\\beta}) - s_i (\\frac{y_i}{s_i} - e^{x_i^T \\hat{\\beta}}) )\\right] = 2\\sum_{i=1}^n \\left[ y_i ln(\\frac{y_i}{\\hat{\\mu_i}}) - (y_i - \\hat{\\mu_i})\\right]\n",
        "$$"
      ],
      "metadata": {
        "id": "wjGN5lKhngFb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "zGFPUzZwFWmg"
      },
      "source": [
        "# 'deaths' is the observed values\n",
        "y = df['deaths']\n",
        "\n",
        "# Calculate the predicted values from the model\n",
        "mu_hat = mdl_1.predict()\n",
        "\n",
        "# Calculate deviance for each observation\n",
        "dev = y * np.log(y / mu_hat) - (y - mu_hat)\n",
        "\n",
        "# Calculate the sum of deviance, multiplied by 2\n",
        "dev_stat = 2 * np.sum(dev)\n",
        "print(\"Deviance Statistic:\", dev_stat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "HXmL-BePFWmg"
      },
      "source": [
        "We get the same value as using the glm() function.\n",
        "\n",
        "We will also test the significance of the interaction using a formula derived in the lecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the predicted values from model 0\n",
        "mu_tilde = mdl_0.predict()\n",
        "\n",
        "# Calculate the manual deviance statistic\n",
        "dev = y * np.log(mu_hat / mu_tilde) - (mu_hat - mu_tilde)\n",
        "dev_stat = 2 * np.sum(dev)\n",
        "print(\"Manual Deviance Statistic:\", dev_stat)\n",
        "\n",
        "# Compute the difference in deviance from the fitted models for verification\n",
        "deviance_diff = mdl_0.deviance - mdl_1.deviance\n",
        "print(\"Deviance Difference from sm.glm: (mdl_0 - mdl_1):\", deviance_diff)\n"
      ],
      "metadata": {
        "id": "Csg6-mjzMFDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "7xDSYHJ8FWmg"
      },
      "source": [
        "\n",
        "for the critical value of the test it holds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "Up3dS3TwFWmh"
      },
      "source": [
        "# Calculate the critical value for a chi-squared distribution at the 5% significance level and 1 degree of freedom\n",
        "c_val = chi2.ppf(0.95, 1)  # Using 0.95 for the upper tail, equivalent to R's lower.tail = FALSE with 0.05\n",
        "print(\"Critical value (c_val):\", c_val)\n",
        "\n",
        "# Calculate the p-value for the chi-squared test statistic\n",
        "p_val = chi2.sf(dev_stat, 1)  # 'sf' is the survival function, equivalent to 1-cdf, and matches R's lower.tail = FALSE\n",
        "print(\"P-value (p_val):\", p_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "zaLDxEtdFWmh"
      },
      "source": [
        "therefore, the interaction is significant in the model. Alternatively, we can use directly the anova() function,\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anova = Anova()\n",
        "\n",
        "anova(mdl_0, mdl_1, test='chisq')"
      ],
      "metadata": {
        "id": "IBG_JTXmMuRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7W3n6OJFWmi"
      },
      "source": [
        "\n",
        "which returns the same result.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "GV3LayURFWmi"
      },
      "source": [
        "## Analysis of Model 1\n",
        "\n",
        "\n",
        "Scatterplot for observed and predicted values of the explained variable\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y, mu_hat, color='red', s=10)  # Scatter plot of observed vs. predicted\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'b--', lw=2)  # Line y=x\n",
        "plt.xlabel('Observed Deaths')\n",
        "plt.ylabel('Predicted Deaths')\n",
        "plt.title('Observed vs. Predicted')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "itFkmDJjNldo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "xCO2un9cFWmi"
      },
      "source": [
        "The observed and predicted values correspond very well.\n",
        "\n",
        "Residual plots\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    Y = mdl_1.model.endog\n",
        "    mu_hat = mdl_1.fittedvalues\n",
        "    phi_hat = mdl_1.scale\n",
        "    var_weights = mdl_1.model.var_weights if mdl_1.model.var_weights is not None else np.ones_like(Y)\n",
        "    V = mdl_1.family.variance(mu_hat)\n",
        "\n",
        "    # Compute leverage values\n",
        "    influence = mdl_1.get_influence(observed=False)  # Adjust as necessary for your model\n",
        "    h_ii = influence.hat_matrix_diag  # Leverage values\n",
        "\n",
        "    # Working Residuals\n",
        "    working_residuals = mdl_1.resid_working\n",
        "\n",
        "    # Pearson Residuals\n",
        "    pearson_residuals = (Y - mu_hat) / np.sqrt(var_weights * V)\n",
        "\n",
        "    # Pearson Standardized Residuals\n",
        "    pearson_standardized_residuals = pearson_residuals / np.sqrt(phi_hat * (1 - h_ii))\n",
        "\n",
        "    # Calculate  Pearson residuals from mdl_1\n",
        "    r_ps = mdl_1.resid_pearson\n",
        "    # Deviance Residuals\n",
        "    deviance_residuals = mdl_1.resid_deviance\n",
        "\n",
        "    # Deviance Standardized Residuals\n",
        "    deviance_standardized_residuals = deviance_residuals / np.sqrt(phi_hat * (1 - h_ii))"
      ],
      "metadata": {
        "id": "OQQVJi4WTqu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6oigrAbS6BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7F_UkintTL3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the plot area\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n",
        "fig.suptitle('Residual Plots')\n",
        "\n",
        "# Residuals vs. Fitted Values\n",
        "axs[0, 0].scatter(mu_hat, r_ps, color='red', s=13)\n",
        "axs[0, 0].axhline(0, color='black', lw=2)\n",
        "axs[0, 0].set_title('Residuals vs. Fitted Values')\n",
        "axs[0, 0].set_xlabel('Fitted Values')\n",
        "axs[0, 0].set_ylabel('Standardized Residuals')\n",
        "\n",
        "# Residuals vs. Age Category\n",
        "axs[0, 1].scatter(data_poiss['agecat'], r_ps, color='red', s=13)\n",
        "axs[0, 1].axhline(0, color='black', lw=2)\n",
        "axs[0, 1].set_title('Residuals vs. Age Category')\n",
        "axs[0, 1].set_xlabel('Age Category')\n",
        "\n",
        "# Residuals vs. Smoke\n",
        "axs[1, 0].scatter(data_poiss['smoke'], r_ps, color='red', s=13)\n",
        "axs[1, 0].axhline(0, color='black', lw=2)\n",
        "axs[1, 0].set_title('Residuals vs. Smoke')\n",
        "axs[1, 0].set_xlabel('Smoke')\n",
        "\n",
        "# QQ Plot of the Residuals\n",
        "sm.qqplot(deviance_standardized_residuals, line='45', ax=axs[1, 1], color='red')\n",
        "axs[1, 1].set_title('QQ-plot of Residuals')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ofoJ1UeVN-VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig.align": "center",
        "fig.height": 7,
        "fig.width": 7,
        "lines_to_next_cell": 0,
        "results": "asis",
        "id": "7aTV02XcFWmi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "xvi33uPBFWmj"
      },
      "source": [
        "given the small number of observations, no significant problem is visible here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "ANyeD2uVFWmj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "uGlzAQs3FWmj"
      },
      "source": [
        "**Influential observations and leverage points**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cook's distance\n",
        "c_d = mdl_1.get_influence().cooks_distance[0]\n",
        "\n",
        "# Leverage values\n",
        "lev = mdl_1.get_influence().hat_matrix_diag\n",
        "\n",
        "# Set up the plot area\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot Cook's distance\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(range(len(c_d)), c_d, color='red', s=13)\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel(\"Cook's Distance\")\n",
        "plt.title(\"Cook's Distance\")\n",
        "plt.ylim(0, 2.1)\n",
        "\n",
        "# Add horizontal line at 8/(n-2*p)\n",
        "plt.axhline(8/(len(mdl_1.model.endog - 2*mdl_1.df_model)), color='blue', linestyle='--')\n",
        "\n",
        "\n",
        "# Plot leverage values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(range(len(lev)), lev, color='red', s=13)\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Leverage')\n",
        "plt.title('Leverage Values')\n",
        "plt.ylim(0, 1.2)\n",
        "\n",
        "# Add horizontal line at 2*p/n for leverage plot\n",
        "plt.axhline(2 * mdl_1.df_model / len(mdl_1.model.endog), color='blue', linestyle='--')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WxdS7-4aU_gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "Nnum6w3gFWmk"
      },
      "source": [
        "In neither case do we see suspiciously large values\n",
        "\n",
        "**Interpretation of parameters**\n",
        "\n",
        "Let's calculate the relative risks in Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "woiv5o3wFWmk"
      },
      "source": [
        "# Extract estimated coefficients\n",
        "par_est_1 = mdl_1.params\n",
        "\n",
        "# Display estimated coefficients\n",
        "print(\"Estimated coefficients:\\n\", par_est_1)\n",
        "\n",
        "# Calculate relative risks\n",
        "RR_1 = np.exp(par_est_1)\n",
        "\n",
        "# Display relative risks\n",
        "print(\"Relative risks:\\n\", RR_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aow3d508XaYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "EOHiE05dFWmk"
      },
      "source": [
        "Discussion of the obtained values and calculation of relative risks for individual age categories are provided in Section 7.7 of the lecture materials.\n",
        "\n",
        "For Model 0 without interactions, the situation is simpler, and it is easy to obtain estimates of RR and corresponding confidence intervals."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VnhIU4w4XplF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract coefficients and confidence intervals\n",
        "coefficients = mdl_1.params\n",
        "conf_intervals = mdl_1.conf_int()\n",
        "\n",
        "# Calculate exponential of coefficients and confidence intervals\n",
        "exp_values = np.exp(np.concatenate((coefficients.values.reshape(-1, 1), conf_intervals), axis=1))\n",
        "\n",
        "# Create a DataFrame\n",
        "df_exp_values = pd.DataFrame(exp_values, columns=['Estimated Values', 'Lower CI', 'Upper CI'], index=coefficients.index)\n",
        "\n",
        "# Add parameter names as a separate column\n",
        "df_exp_values['Parameter Names'] = coefficients.index\n",
        "\n",
        "# Reorder the columns\n",
        "df_exp_values = df_exp_values[['Parameter Names', 'Estimated Values', 'Lower CI', 'Upper CI']]\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_exp_values)\n"
      ],
      "metadata": {
        "id": "G4aNJWVkXbNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu_hat"
      ],
      "metadata": {
        "id": "isJXi5gDJmlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK-miqw-FWmk"
      },
      "source": [
        "Plots:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['y'] = df['deaths']\n",
        "\n",
        "df['mu_tilde'] = mu_tilde\n",
        "df['mu_hat'] = mu_hat\n",
        "\n"
      ],
      "metadata": {
        "id": "nMUL-GfsETBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "-_4l3UE33MEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['y_scaled'] = df['y'] / df['person_years'] * 100000\n",
        "df['smoke'] = pd.Categorical(df['smoke'], categories=[\"1\", \"0\"], ordered=True)\n",
        "df['color'] = df['smoke'].map({\"1\": \"red\", \"0\": \"blue\"})\n",
        "df['marker'] = df['smoke'].map({\"1\": 15, \"0\": 16})\n",
        "\n",
        "# Prepare scaled models output\n",
        "df['mu_tilde_scaled'] = df['mu_tilde'] / df['person_years'] * 100000\n",
        "df['mu_hat_scaled'] = df['mu_hat'] / df['person_years'] * 100000\n",
        "\n",
        "# Splitting data for plotting based on smoke status for lines\n",
        "grouped = df.groupby('smoke')\n",
        "\n",
        "# Setup the plot with 2 subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
        "\n",
        "# Plot for Model 0 without interaction\n",
        "axes[0].scatter(df['agecat'], df['y_scaled'], c=df['color'], marker='o', label=df['smoke'])\n",
        "for name, group in grouped:\n",
        "    axes[0].plot(group['agecat'], group['mu_tilde_scaled'], color=group['color'].iloc[0], linewidth=2)\n",
        "axes[0].set_title('Model 0 without interaction')\n",
        "axes[0].set_xlabel('Age group')\n",
        "axes[0].set_ylabel('Deaths per 100,000 person-years')\n",
        "axes[0].legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Smokers'),\n",
        "                        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Non-smokers')], loc='upper left')\n",
        "\n",
        "# Plot for Model 1 with interaction\n",
        "axes[1].scatter(df['agecat'], df['y_scaled'], c=df['color'], marker='o', label=df['smoke'])\n",
        "for name, group in grouped:\n",
        "    axes[1].plot(group['agecat'], group['mu_hat_scaled'], color=group['color'].iloc[0], linewidth=2)\n",
        "axes[1].set_title('Model 1 with interaction')\n",
        "axes[1].set_xlabel('Age group')\n",
        "axes[1].set_ylabel('Deaths per 100,000 person-years')\n",
        "axes[1].legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Smokers'),\n",
        "                        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Non-smokers')], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E4KZSt1J22ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming df is your DataFrame and it's already defined\n",
        "\n",
        "# Scale 'y' by 'person_years' and multiply by 100000\n",
        "df['y_scaled'] = df['y'] / df['person_years'] * 100000\n",
        "\n",
        "# Setting 'smoke' as a categorical variable with a specific order\n",
        "df['smoke'] = pd.Categorical(df['smoke'], categories=[\"1\", \"0\"], ordered=True)\n",
        "\n",
        "# Map 'smoke' to colors and markers\n",
        "df['color'] = df['smoke'].map({\"1\": \"red\", \"0\": \"blue\"})\n",
        "\n",
        "# Prepare scaled models output\n",
        "df['mu_tilde_scaled'] = df['mu_tilde'] / df['person_years'] * 100000\n",
        "df['mu_hat_scaled'] = df['mu_hat'] / df['person_years'] * 100000\n",
        "\n",
        "# Group data by 'smoke' status for plotting\n",
        "grouped = df.groupby('smoke')\n",
        "\n",
        "# Setup the plot with 2 subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
        "\n",
        "# Plot for Model 0 without interaction\n",
        "for name, group in grouped:\n",
        "    axes[0].scatter(group['agecat'], group['y_scaled'], c=group['color'], marker='o', alpha=0.7)\n",
        "    axes[0].plot(group['agecat'], group['mu_tilde_scaled'], color=group['color'].iloc[0], linewidth=2)\n",
        "\n",
        "axes[0].set_title('Model 0 without interaction')\n",
        "axes[0].set_xlabel('Age group')\n",
        "axes[0].set_ylabel('Deaths per 100,000 person-years')\n",
        "axes[0].legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Smokers'),\n",
        "                        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Non-smokers')], loc='upper left')\n",
        "\n",
        "# Plot for Model 1 with interaction\n",
        "for name, group in grouped:\n",
        "    axes[1].scatter(group['agecat'], group['y_scaled'], c=group['color'], marker='o', alpha=0.7)\n",
        "    axes[1].plot(group['agecat'], group['mu_hat_scaled'], color=group['color'].iloc[0], linewidth=2)\n",
        "\n",
        "axes[1].set_title('Model 1 with interaction')\n",
        "axes[1].set_xlabel('Age group')\n",
        "axes[1].set_ylabel('Deaths per 100,000 person-years')\n",
        "axes[1].legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Smokers'),\n",
        "                        plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Non-smokers')], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xr2hhOxqOjTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kfB2cm92gO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rS75Nwcb2gRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTxiOYzf2gUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUWVkH4h2gWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uv9Pza5R2gYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task:\n",
        "* Try to model with and without offset. Compare results, why to use/ not use offset?\n",
        "* Try Poisson distribution with factor variables (contingency tables approach).\n",
        "\n"
      ],
      "metadata": {
        "id": "zN4qebVOGqQ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your turn: HW\n",
        "\n",
        "Exercise 9.2 from\n",
        "(https://reneues.files.wordpress.com/2010/01/an-introduction-to-generalized-linear-models-second-edition-dobson.pdf)\n",
        "\n",
        "In the dataframe data(insurance) you have numbers of insurance policies, `n`, and numbers of\n",
        "claims, `y`, for cars in various insurance categories, `car`, tabulated by age of policy holder, `age`, and district where the policy holder lived `district` (district = 1,for London and other major cities and district = 0, otherwise). The dataset is derived from the CLAIMS data set in Aitkin et al. (1989) obtained from a paper by Baxter, Coutts and Ross (1980).\n",
        "\n",
        "* Calculate the rate ofclaims y/n for each category and plot the rates by\n",
        "AGE, CAR and DIST to get an idea ofthe main effects ofthese factors.\n",
        "* Use Poisson regression to estimate the main effects (each treated as categorical and modelled using indicator variables) and interaction terms.\n",
        "* Based on the modelling in (b), Aitkin et al. (1989) determined that all the interactions were unimportant and decided that AGE and CAR could be\n",
        "treated as though they were continuous variables. Fit a model incorporating\n",
        "these features and compare it with the best model obtained in (b). What\n",
        "conclusions do you reach?"
      ],
      "metadata": {
        "id": "rE5CCaqsCrlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the dataset"
      ],
      "metadata": {
        "id": "xtAmM3hWawvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R -o insurance\n",
        "install.packages(\"dobson\")\n",
        "library(dobson)\n",
        "\n",
        "data(insurance)\n",
        "insurance\n",
        "? insurance"
      ],
      "metadata": {
        "id": "PPyixxRNCuvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Elementary statistics"
      ],
      "metadata": {
        "id": "XF633Dsva1uP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "insurance.describe()"
      ],
      "metadata": {
        "id": "Yw_MD2EiDAb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = insurance.copy()\n",
        "#dataset2 = insurance.copy()\n",
        "\n",
        "dataset['car'] = dataset['car'].astype('category')\n",
        "dataset['district'] = dataset['district'].astype('category')\n",
        "dataset['age'] = dataset['age'].astype('category')\n",
        "\n",
        "#dataset2['district'] = dataset2['district'].astype('category')\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "8FvMwnL_DOLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#is_factor_smoke = pd.api.types.is_categorical_dtype(dataset2['car'])\n",
        "#print(is_factor_smoke)"
      ],
      "metadata": {
        "id": "l_nzrHg_p1uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Rate of claims\n",
        "\n",
        "\n",
        "*   decreasing claim rate by age\n",
        "*   increasing claim rate by car\n",
        "*   increasing claim rate by district\n",
        "\n"
      ],
      "metadata": {
        "id": "-qrs8oyca-K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you already have the insurance_df DataFrame loaded\n",
        "\n",
        "# Calculate the rate of claims (y/n) for each category\n",
        "dataset['claim_rate'] = dataset['y'] / dataset['n']\n",
        "\n",
        "# Plot the rates by age\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='age', y='claim_rate', data=dataset)\n",
        "plt.title('Claim Rate by Age')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Claim Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plot the rates by car\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='car', y='claim_rate', data=dataset)\n",
        "plt.title('Claim Rate by Car')\n",
        "plt.xlabel('Car Insurance Category')\n",
        "plt.ylabel('Claim Rate')\n",
        "plt.show()\n",
        "\n",
        "# Plot the rates by district\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='district', y='claim_rate', data=dataset)\n",
        "plt.title('Claim Rate by District')\n",
        "plt.xlabel('District')\n",
        "plt.ylabel('Claim Rate')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tms3vu-zXiZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Full model\n",
        "One can see that the model contains many of insignificant variables."
      ],
      "metadata": {
        "id": "Sr04LkhbcqEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the offset\n",
        "offset = np.log((dataset['y']+1) / (dataset['n']+1))\n",
        "\n",
        "# Define the model formula\n",
        "formula1 = 'y ~ age + car + district + age:car + age:district + car:district'\n",
        "\n",
        "# Fit the Poisson regression model with the Log link function\n",
        "mdl_f = smf.glm(formula=formula1, data=dataset, offset = offset,\n",
        "                family=sm.families.Poisson(link=sm.families.links.Log())).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl_f.summary())"
      ],
      "metadata": {
        "id": "D0KcIwwjXkQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Simplier model\n",
        "This model describes less deviance, while having all variables significant."
      ],
      "metadata": {
        "id": "eTNkKqkodFzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the offset\n",
        "offset = np.log((dataset['y']+1) / (dataset['n']+1))\n",
        "\n",
        "# Define the model formula\n",
        "formula2 = 'y ~ age + car + district'\n",
        "\n",
        "# Fit the Poisson regression model with the Log link function\n",
        "mdl_s = smf.glm(formula=formula2, data=dataset, offset = offset,\n",
        "                family=sm.families.Poisson(link=sm.families.links.Log())).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl_s.summary())"
      ],
      "metadata": {
        "id": "LjYp1uykXoBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analysis of simplier model"
      ],
      "metadata": {
        "id": "nyHp6jt5k6FW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the Anova method, one can see that the utilizing the interactions in the full model can be obtained better model. The null hypothesis that the models are equal is rejected with $p$-value of 0,02."
      ],
      "metadata": {
        "id": "73Mw7fMkfP_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anova = Anova()\n",
        "\n",
        "anova(mdl_f, mdl_s, test='chisq')"
      ],
      "metadata": {
        "id": "65Vb2BSZepUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset['y']\n",
        "mu_hat = mdl_s.predict()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.scatter(y, mu_hat, color='red', s=10)  # Scatter plot of observed vs. predicted\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'b--', lw=2)  # Line y=x\n",
        "plt.xlabel('Observed claims')\n",
        "plt.ylabel('Predicted claims')\n",
        "plt.title('Observed vs. Predicted')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eYLysdkBgUXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_plot(dataset, mod):\n",
        "    Y = mod.model.endog\n",
        "    mu_hat = mod.fittedvalues\n",
        "    phi_hat = mod.scale\n",
        "    var_weights = mod.model.var_weights if mod.model.var_weights is not None else np.ones_like(Y)\n",
        "    V = mod.family.variance(mu_hat)\n",
        "\n",
        "    # Compute leverage values\n",
        "    influence = mod.get_influence(observed=False)  # Adjust as necessary for your model\n",
        "    h_ii = influence.hat_matrix_diag  # Leverage values\n",
        "\n",
        "    # Working Residuals\n",
        "    working_residuals = mod.resid_working\n",
        "\n",
        "    # Pearson Residuals\n",
        "    pearson_residuals = (Y - mu_hat) / np.sqrt(var_weights * V)\n",
        "\n",
        "    # Pearson Standardized Residuals\n",
        "    pearson_standardized_residuals = pearson_residuals / np.sqrt(phi_hat * (1 - h_ii))\n",
        "\n",
        "    # Calculate  Pearson residuals from mdl_1\n",
        "    r_ps = mod.resid_pearson\n",
        "    # Deviance Residuals\n",
        "    deviance_residuals = mod.resid_deviance\n",
        "\n",
        "    # Deviance Standardized Residuals\n",
        "    deviance_standardized_residuals = deviance_residuals / np.sqrt(phi_hat * (1 - h_ii))\n",
        "\n",
        "    # Setting up the plot area\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "    fig.suptitle('Residual Plots')\n",
        "\n",
        "    # Residuals vs. Fitted Values\n",
        "    axs[0, 0].scatter(mu_hat, r_ps, color='red', s=13)\n",
        "    axs[0, 0].axhline(0, color='black', lw=2)\n",
        "    axs[0, 0].set_title('Residuals vs. Fitted Values')\n",
        "    axs[0, 0].set_xlabel('Fitted Values')\n",
        "    axs[0, 0].set_ylabel('Standardized Residuals')\n",
        "\n",
        "    # Residuals vs. Age Category\n",
        "    axs[0, 1].scatter(dataset['age'], r_ps, color='red', s=13)\n",
        "    axs[0, 1].axhline(0, color='black', lw=2)\n",
        "    axs[0, 1].set_title('Residuals vs. Age Category')\n",
        "    axs[0, 1].set_xlabel('Age Category')\n",
        "\n",
        "    # Residuals vs. Smoke\n",
        "    axs[1, 0].scatter(dataset['car'], r_ps, color='red', s=13)\n",
        "    axs[1, 0].axhline(0, color='black', lw=2)\n",
        "    axs[1, 0].set_title('Residuals vs. Car Category')\n",
        "    axs[1, 0].set_xlabel('Car category')\n",
        "\n",
        "    # QQ Plot of the Residuals\n",
        "    sm.qqplot(deviance_standardized_residuals, line='45', ax=axs[1, 1], color='red')\n",
        "    axs[1, 1].set_title('QQ-plot of Residuals')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "def cook_infl(mod):\n",
        "  # Cook's distance\n",
        "  c_d = mod.get_influence().cooks_distance[0]\n",
        "\n",
        "  # Leverage values\n",
        "  lev = mod.get_influence().hat_matrix_diag\n",
        "\n",
        "  # Set up the plot area\n",
        "  plt.figure(figsize=(10, 5))\n",
        "\n",
        "  # Plot Cook's distance\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.scatter(range(len(c_d)), c_d, color='red', s=13)\n",
        "  plt.xlabel('Index')\n",
        "  plt.ylabel(\"Cook's Distance\")\n",
        "  plt.title(\"Cook's Distance\")\n",
        "  plt.ylim(0, 2.1)\n",
        "\n",
        "  # Add horizontal line at 8/(n-2*p)\n",
        "  plt.axhline(8/(len(mod.model.endog - 2*mod.df_model)), color='blue', linestyle='--')\n",
        "\n",
        "\n",
        "  # Plot leverage values\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.scatter(range(len(lev)), lev, color='red', s=13)\n",
        "  plt.xlabel('Index')\n",
        "  plt.ylabel('Leverage')\n",
        "  plt.title('Leverage Values')\n",
        "  plt.ylim(0, 1.2)\n",
        "\n",
        "  # Add horizontal line at 2*p/n for leverage plot\n",
        "  plt.axhline(2 * mod.df_model / len(mod.model.endog), color='blue', linestyle='--')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "KbRw6rMsCMx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual_plot(dataset, mdl_s)\n",
        "cook_infl(mdl_s)"
      ],
      "metadata": {
        "id": "V5Nd4n0PlP4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model without the 'outlier'"
      ],
      "metadata": {
        "id": "6zmfSp87HPK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the first observation using iloc\n",
        "dataset_cleaned = dataset.drop(dataset.index[0])\n",
        "\n",
        "# Define the offset\n",
        "offset = np.log((dataset_cleaned['y']+1) / (dataset_cleaned['n']+1))\n",
        "\n",
        "# Fit the Poisson regression model with the Log link function\n",
        "mdl_n = smf.glm(formula=formula2, data=dataset_cleaned, offset = offset,\n",
        "                family=sm.families.Poisson(link=sm.families.links.Log())).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(mdl_n.summary())\n",
        "\n",
        "residual_plot(dataset_cleaned, mdl_n)\n",
        "cook_infl(mdl_n)"
      ],
      "metadata": {
        "id": "gYRLG5HnACLa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}